# âœ… RAG Example Validation Guide

This guide helps you verify that the RAG example is working correctly.

## ğŸ” Quick Validation Checklist

- [ ] VectorAI DB is running
- [ ] Python dependencies installed
- [ ] Python client (cortex) installed
- [ ] RAG example runs without errors
- [ ] Embeddings are generated
- [ ] Vectors are stored in database
- [ ] Search returns relevant results
- [ ] Output shows all expected steps

## ğŸ“‹ Step-by-Step Validation

### Step 1: Verify VectorAI DB is Running

```bash
# Check if Docker container is running
docker ps | grep vectoraidb
```

**Expected output:**
```
CONTAINER ID   IMAGE                              STATUS
abc123def456   actian/vectoraidb:latest           Up 2 minutes
```

**If not running:**
```bash
docker compose up -d
```

### Step 2: Verify Python Environment

```bash
# Check Python version (3.8+ required)
python --version

# Should show Python 3.8 or higher
```

### Step 3: Install Dependencies

```bash
# From the project root directory
pip install actiancortex-0.1.0b1-py3-none-any.whl
pip install -r examples/rag/requirements.txt
```

**Expected output:**
```
Successfully installed sentence-transformers-X.X.X
Successfully installed openai-X.X.X
...
```

### Step 4: Run the RAG Example (Local Mode)

This tests the core functionality without requiring an API key:

```bash
python examples/rag/rag_example.py --local
```

### Step 5: Verify Expected Output

The script should produce output similar to this:

```
======================================================================
ğŸš€ End-to-End RAG Example with Actian VectorAI DB
======================================================================

ğŸ“¥ Step 1: Loading embedding model...
   (This may take a moment on first run)
   âœ“ Model loaded: all-MiniLM-L6-v2 (384 dimensions)

ğŸ”Œ Step 2: Connecting to VectorAI DB at localhost:50051...
   âœ“ Connected to VectorAI DB v1.0

ğŸ’¾ Step 3: Creating collection 'rag_demo_XXXXXXXX'...
   âœ“ Collection created with COSINE similarity

ğŸ“„ Step 4: Processing and chunking documents...
   âœ“ Created X text chunks

ğŸ§  Step 5: Generating embeddings and storing in database...
   âœ“ Stored X document chunks with embeddings
   âœ“ Verified: X vectors in database

======================================================================
ğŸ” RAG Query Examples
======================================================================

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Query 1: What are the key features of Actian VectorAI DB?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  1ï¸âƒ£  Embedding query...
  2ï¸âƒ£  Retrieving relevant context from VectorAI DB...
     Found 3 relevant chunks:
       â€¢ Chunk 1 (similarity: 0.XXXX)
       â€¢ Chunk 2 (similarity: 0.XXXX)
       â€¢ Chunk 3 (similarity: 0.XXXX)
  3ï¸âƒ£  Generating answer...

  ğŸ“ Answer:
     Based on the retrieved context...

[... more queries ...]

======================================================================
ğŸ§¹ Cleanup
======================================================================
âœ“ Collection 'rag_demo_XXXXXXXX' deleted

======================================================================
âœ… RAG Example Completed Successfully!
======================================================================
```

### Step 6: Validation Checks

#### âœ… SUCCESS Indicators:

1. **All steps complete** - No errors or exceptions
2. **Model loads** - "Model loaded: all-MiniLM-L6-v2"
3. **Database connects** - "Connected to VectorAI DB"
4. **Collection created** - "Collection created"
5. **Vectors stored** - "Stored X document chunks"
6. **Search works** - "Found 3 relevant chunks"
7. **Similarity scores** - Scores between 0.5-1.0 (high similarity)
8. **Cleanup works** - "Collection deleted"

#### âŒ FAILURE Indicators:

- Connection errors â†’ Database not running
- Import errors â†’ Dependencies not installed
- gRPC errors â†’ Port 50051 not accessible
- Low similarity scores (< 0.3) â†’ Embedding issue

## ğŸ§ª Advanced Validation (With OpenAI)

If you have an OpenAI API key:

```bash
# Windows PowerShell
$env:OPENAI_API_KEY="your-key-here"
python examples/rag/rag_example.py

# Linux/macOS
export OPENAI_API_KEY="your-key-here"
python examples/rag/rag_example.py

# Windows CMD
set OPENAI_API_KEY=your-key-here
python examples/rag/rag_example.py
```

**Expected difference:**
The answers should be more natural and coherent (generated by GPT-3.5) instead of just showing the retrieved context.

## ğŸ”§ Troubleshooting

### Issue: "Connection refused" or "failed to connect"

**Cause:** VectorAI DB not running

**Solution:**
```bash
docker compose up -d
docker logs vectoraidb  # Check logs for errors
```

### Issue: "No module named 'sentence_transformers'"

**Cause:** Dependencies not installed

**Solution:**
```bash
pip install sentence-transformers
```

### Issue: "No module named 'cortex'"

**Cause:** Python client not installed

**Solution:**
```bash
pip install actiancortex-0.1.0b1-py3-none-any.whl
```

### Issue: Script runs but similarity scores are very low (< 0.3)

**Cause:** This is expected on first run - the model uses random seeds

**Solution:** Run the script again, scores should be consistent

### Issue: "Model download failed" or slow first run

**Cause:** First run downloads the embedding model (~80MB)

**Solution:** Wait for download to complete, subsequent runs will be fast

### Issue: OpenAI API errors

**Cause:** API key not set or invalid

**Solution:**
```bash
# Check if key is set
echo $OPENAI_API_KEY  # Linux/macOS
echo %OPENAI_API_KEY%  # Windows CMD

# Or just use local mode
python examples/rag/rag_example.py --local
```

## ğŸ“Š Performance Benchmarks

On a typical machine, you should see:

- **Model loading:** 2-10 seconds (first run: 30-60s for download)
- **Embedding 10-20 chunks:** 1-3 seconds
- **Database operations:** < 1 second
- **Search queries:** < 100ms each
- **Total runtime:** 10-30 seconds

## âœ… Final Validation Checklist

Run through this checklist to ensure everything works:

```bash
# 1. Database is running
docker ps | grep vectoraidb
# âœ“ Should show running container

# 2. Dependencies installed
pip list | grep sentence-transformers
pip list | grep cortex
# âœ“ Both should be listed

# 3. Run example
python examples/rag/rag_example.py --local
# âœ“ Should complete with "âœ… RAG Example Completed Successfully!"

# 4. Check similarity scores in output
# âœ“ Should see scores > 0.5 for relevant matches

# 5. Verify cleanup
# âœ“ Script should delete collection at the end
```

## ğŸ¯ Success Criteria

Your RAG example is working correctly if:

1. âœ… Script runs from start to finish without errors
2. âœ… All 3 example queries complete successfully
3. âœ… Similarity scores are reasonable (> 0.5 for top matches)
4. âœ… Retrieved chunks are semantically relevant to queries
5. âœ… Collection is created and deleted cleanly

## ğŸ“ Manual Testing

Want to test with your own query? Modify the script:

```python
# In rag_example.py, find this section:
queries = [
    "What are the key features of Actian VectorAI DB?",
    "How do I get started with the database?",
    "What distance metrics are supported?",
]

# Add your own query:
queries = [
    "What are the key features of Actian VectorAI DB?",
    "How do I get started with the database?",
    "What distance metrics are supported?",
    "YOUR CUSTOM QUERY HERE",  # â† Add this
]
```

## ğŸš€ Next Steps After Validation

Once validated, you can:

1. **Customize with your data** - Replace `KNOWLEDGE_BASE` with your documents
2. **Try different models** - Use larger/better embedding models
3. **Integrate into your app** - Use this as a template
4. **Scale up** - Add thousands of documents
5. **Add filtering** - Use the Filter DSL for metadata filtering

---

**Need help?** Check the [README.md](README.md) or [WORKFLOW.md](WORKFLOW.md) for more details.
